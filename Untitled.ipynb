{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
       "       'species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('species',axis=1)\n",
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "\n",
    "# Last layer for multi-class classification of 3 species\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/300\n",
      "120/120 [==============================] - 0s 3ms/sample - loss: 1.1583 - accuracy: 0.3333 - val_loss: 1.0721 - val_accuracy: 0.4000\n",
      "Epoch 2/300\n",
      "120/120 [==============================] - 0s 159us/sample - loss: 1.1494 - accuracy: 0.3333 - val_loss: 1.0678 - val_accuracy: 0.4333\n",
      "Epoch 3/300\n",
      "120/120 [==============================] - 0s 205us/sample - loss: 1.1418 - accuracy: 0.3583 - val_loss: 1.0635 - val_accuracy: 0.4333\n",
      "Epoch 4/300\n",
      "120/120 [==============================] - 0s 206us/sample - loss: 1.1345 - accuracy: 0.3750 - val_loss: 1.0593 - val_accuracy: 0.5333\n",
      "Epoch 5/300\n",
      "120/120 [==============================] - 0s 171us/sample - loss: 1.1266 - accuracy: 0.3833 - val_loss: 1.0553 - val_accuracy: 0.6000\n",
      "Epoch 6/300\n",
      "120/120 [==============================] - 0s 190us/sample - loss: 1.1200 - accuracy: 0.4333 - val_loss: 1.0515 - val_accuracy: 0.6000\n",
      "Epoch 7/300\n",
      "120/120 [==============================] - 0s 180us/sample - loss: 1.1126 - accuracy: 0.4583 - val_loss: 1.0478 - val_accuracy: 0.6333\n",
      "Epoch 8/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 1.1067 - accuracy: 0.4833 - val_loss: 1.0442 - val_accuracy: 0.6667\n",
      "Epoch 9/300\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 1.0996 - accuracy: 0.5167 - val_loss: 1.0406 - val_accuracy: 0.6667\n",
      "Epoch 10/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 1.0935 - accuracy: 0.5500 - val_loss: 1.0371 - val_accuracy: 0.6667\n",
      "Epoch 11/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 1.0872 - accuracy: 0.5667 - val_loss: 1.0337 - val_accuracy: 0.6667\n",
      "Epoch 12/300\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 1.0816 - accuracy: 0.5667 - val_loss: 1.0303 - val_accuracy: 0.6667\n",
      "Epoch 13/300\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 1.0760 - accuracy: 0.6083 - val_loss: 1.0268 - val_accuracy: 0.7000\n",
      "Epoch 14/300\n",
      "120/120 [==============================] - 0s 181us/sample - loss: 1.0698 - accuracy: 0.6250 - val_loss: 1.0232 - val_accuracy: 0.7000\n",
      "Epoch 15/300\n",
      "120/120 [==============================] - 0s 219us/sample - loss: 1.0645 - accuracy: 0.6333 - val_loss: 1.0198 - val_accuracy: 0.7333\n",
      "Epoch 16/300\n",
      "120/120 [==============================] - 0s 181us/sample - loss: 1.0592 - accuracy: 0.6500 - val_loss: 1.0163 - val_accuracy: 0.7333\n",
      "Epoch 17/300\n",
      "120/120 [==============================] - 0s 203us/sample - loss: 1.0537 - accuracy: 0.6500 - val_loss: 1.0129 - val_accuracy: 0.7333\n",
      "Epoch 18/300\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 1.0486 - accuracy: 0.6500 - val_loss: 1.0095 - val_accuracy: 0.7333\n",
      "Epoch 19/300\n",
      "120/120 [==============================] - 0s 187us/sample - loss: 1.0434 - accuracy: 0.6500 - val_loss: 1.0061 - val_accuracy: 0.7333\n",
      "Epoch 20/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 1.0383 - accuracy: 0.6500 - val_loss: 1.0027 - val_accuracy: 0.7333\n",
      "Epoch 21/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 1.0334 - accuracy: 0.6500 - val_loss: 0.9993 - val_accuracy: 0.7000\n",
      "Epoch 22/300\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 1.0283 - accuracy: 0.6500 - val_loss: 0.9958 - val_accuracy: 0.7000\n",
      "Epoch 23/300\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 1.0238 - accuracy: 0.6500 - val_loss: 0.9924 - val_accuracy: 0.7000\n",
      "Epoch 24/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 1.0188 - accuracy: 0.6500 - val_loss: 0.9890 - val_accuracy: 0.7000\n",
      "Epoch 25/300\n",
      "120/120 [==============================] - 0s 177us/sample - loss: 1.0139 - accuracy: 0.6417 - val_loss: 0.9855 - val_accuracy: 0.7000\n",
      "Epoch 26/300\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 1.0092 - accuracy: 0.6417 - val_loss: 0.9821 - val_accuracy: 0.7000\n",
      "Epoch 27/300\n",
      "120/120 [==============================] - 0s 163us/sample - loss: 1.0046 - accuracy: 0.6417 - val_loss: 0.9787 - val_accuracy: 0.7000\n",
      "Epoch 28/300\n",
      "120/120 [==============================] - 0s 195us/sample - loss: 0.9996 - accuracy: 0.6417 - val_loss: 0.9752 - val_accuracy: 0.7000\n",
      "Epoch 29/300\n",
      "120/120 [==============================] - 0s 178us/sample - loss: 0.9950 - accuracy: 0.6417 - val_loss: 0.9717 - val_accuracy: 0.7000\n",
      "Epoch 30/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.9903 - accuracy: 0.6417 - val_loss: 0.9682 - val_accuracy: 0.6667\n",
      "Epoch 31/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.9855 - accuracy: 0.6333 - val_loss: 0.9649 - val_accuracy: 0.6667\n",
      "Epoch 32/300\n",
      "120/120 [==============================] - 0s 288us/sample - loss: 0.9810 - accuracy: 0.6250 - val_loss: 0.9615 - val_accuracy: 0.6667\n",
      "Epoch 33/300\n",
      "120/120 [==============================] - 0s 325us/sample - loss: 0.9762 - accuracy: 0.6250 - val_loss: 0.9580 - val_accuracy: 0.6667\n",
      "Epoch 34/300\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 0.9717 - accuracy: 0.6250 - val_loss: 0.9545 - val_accuracy: 0.6667\n",
      "Epoch 35/300\n",
      "120/120 [==============================] - 0s 237us/sample - loss: 0.9670 - accuracy: 0.6250 - val_loss: 0.9509 - val_accuracy: 0.6667\n",
      "Epoch 36/300\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 0.9627 - accuracy: 0.6250 - val_loss: 0.9472 - val_accuracy: 0.6667\n",
      "Epoch 37/300\n",
      "120/120 [==============================] - 0s 529us/sample - loss: 0.9577 - accuracy: 0.6250 - val_loss: 0.9435 - val_accuracy: 0.6667\n",
      "Epoch 38/300\n",
      "120/120 [==============================] - 0s 259us/sample - loss: 0.9533 - accuracy: 0.6250 - val_loss: 0.9398 - val_accuracy: 0.6667\n",
      "Epoch 39/300\n",
      "120/120 [==============================] - 0s 204us/sample - loss: 0.9488 - accuracy: 0.6250 - val_loss: 0.9360 - val_accuracy: 0.6667\n",
      "Epoch 40/300\n",
      "120/120 [==============================] - 0s 205us/sample - loss: 0.9440 - accuracy: 0.6250 - val_loss: 0.9322 - val_accuracy: 0.6667\n",
      "Epoch 41/300\n",
      "120/120 [==============================] - 0s 157us/sample - loss: 0.9395 - accuracy: 0.6250 - val_loss: 0.9284 - val_accuracy: 0.6667\n",
      "Epoch 42/300\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 0.9351 - accuracy: 0.6250 - val_loss: 0.9246 - val_accuracy: 0.6667\n",
      "Epoch 43/300\n",
      "120/120 [==============================] - 0s 205us/sample - loss: 0.9303 - accuracy: 0.6167 - val_loss: 0.9208 - val_accuracy: 0.7000\n",
      "Epoch 44/300\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.9259 - accuracy: 0.6167 - val_loss: 0.9169 - val_accuracy: 0.7000\n",
      "Epoch 45/300\n",
      "120/120 [==============================] - 0s 161us/sample - loss: 0.9212 - accuracy: 0.6167 - val_loss: 0.9130 - val_accuracy: 0.7000\n",
      "Epoch 46/300\n",
      "120/120 [==============================] - 0s 209us/sample - loss: 0.9166 - accuracy: 0.6083 - val_loss: 0.9090 - val_accuracy: 0.7000\n",
      "Epoch 47/300\n",
      "120/120 [==============================] - 0s 320us/sample - loss: 0.9119 - accuracy: 0.6083 - val_loss: 0.9050 - val_accuracy: 0.7000\n",
      "Epoch 48/300\n",
      "120/120 [==============================] - 0s 359us/sample - loss: 0.9073 - accuracy: 0.6083 - val_loss: 0.9012 - val_accuracy: 0.7000\n",
      "Epoch 49/300\n",
      "120/120 [==============================] - 0s 296us/sample - loss: 0.9028 - accuracy: 0.6000 - val_loss: 0.8972 - val_accuracy: 0.7000\n",
      "Epoch 50/300\n",
      "120/120 [==============================] - 0s 397us/sample - loss: 0.8982 - accuracy: 0.6000 - val_loss: 0.8933 - val_accuracy: 0.6667\n",
      "Epoch 51/300\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.8937 - accuracy: 0.6000 - val_loss: 0.8895 - val_accuracy: 0.6333\n",
      "Epoch 52/300\n",
      "120/120 [==============================] - 0s 165us/sample - loss: 0.8890 - accuracy: 0.6000 - val_loss: 0.8856 - val_accuracy: 0.6333\n",
      "Epoch 53/300\n",
      "120/120 [==============================] - 0s 227us/sample - loss: 0.8846 - accuracy: 0.6000 - val_loss: 0.8818 - val_accuracy: 0.6333\n",
      "Epoch 54/300\n",
      "120/120 [==============================] - 0s 159us/sample - loss: 0.8802 - accuracy: 0.6000 - val_loss: 0.8778 - val_accuracy: 0.6333\n",
      "Epoch 55/300\n",
      "120/120 [==============================] - 0s 202us/sample - loss: 0.8756 - accuracy: 0.5917 - val_loss: 0.8740 - val_accuracy: 0.6333\n",
      "Epoch 56/300\n",
      "120/120 [==============================] - 0s 209us/sample - loss: 0.8710 - accuracy: 0.5917 - val_loss: 0.8700 - val_accuracy: 0.6333\n",
      "Epoch 57/300\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.8666 - accuracy: 0.5917 - val_loss: 0.8660 - val_accuracy: 0.6333\n",
      "Epoch 58/300\n",
      "120/120 [==============================] - 0s 195us/sample - loss: 0.8621 - accuracy: 0.5833 - val_loss: 0.8620 - val_accuracy: 0.6333\n",
      "Epoch 59/300\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 0.8576 - accuracy: 0.5833 - val_loss: 0.8581 - val_accuracy: 0.6333\n",
      "Epoch 60/300\n",
      "120/120 [==============================] - 0s 341us/sample - loss: 0.8531 - accuracy: 0.5833 - val_loss: 0.8543 - val_accuracy: 0.6333\n",
      "Epoch 61/300\n",
      "120/120 [==============================] - 0s 385us/sample - loss: 0.8487 - accuracy: 0.5750 - val_loss: 0.8504 - val_accuracy: 0.6333\n",
      "Epoch 62/300\n",
      "120/120 [==============================] - 0s 445us/sample - loss: 0.8443 - accuracy: 0.5750 - val_loss: 0.8463 - val_accuracy: 0.6333\n",
      "Epoch 63/300\n",
      "120/120 [==============================] - 0s 387us/sample - loss: 0.8398 - accuracy: 0.5750 - val_loss: 0.8423 - val_accuracy: 0.6333\n",
      "Epoch 64/300\n",
      "120/120 [==============================] - 0s 400us/sample - loss: 0.8355 - accuracy: 0.5833 - val_loss: 0.8385 - val_accuracy: 0.6333\n",
      "Epoch 65/300\n",
      "120/120 [==============================] - 0s 381us/sample - loss: 0.8310 - accuracy: 0.5833 - val_loss: 0.8344 - val_accuracy: 0.6333\n",
      "Epoch 66/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.8265 - accuracy: 0.5833 - val_loss: 0.8304 - val_accuracy: 0.6333\n",
      "Epoch 67/300\n",
      "120/120 [==============================] - 0s 306us/sample - loss: 0.8224 - accuracy: 0.5833 - val_loss: 0.8264 - val_accuracy: 0.6333\n",
      "Epoch 68/300\n",
      "120/120 [==============================] - 0s 256us/sample - loss: 0.8178 - accuracy: 0.5833 - val_loss: 0.8225 - val_accuracy: 0.6333\n",
      "Epoch 69/300\n",
      "120/120 [==============================] - 0s 261us/sample - loss: 0.8134 - accuracy: 0.5833 - val_loss: 0.8186 - val_accuracy: 0.6333\n",
      "Epoch 70/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.8091 - accuracy: 0.5833 - val_loss: 0.8147 - val_accuracy: 0.6000\n",
      "Epoch 71/300\n",
      "120/120 [==============================] - 0s 190us/sample - loss: 0.8048 - accuracy: 0.5833 - val_loss: 0.8109 - val_accuracy: 0.6000\n",
      "Epoch 72/300\n",
      "120/120 [==============================] - 0s 218us/sample - loss: 0.8005 - accuracy: 0.5833 - val_loss: 0.8072 - val_accuracy: 0.6000\n",
      "Epoch 73/300\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.7963 - accuracy: 0.5667 - val_loss: 0.8035 - val_accuracy: 0.6000\n",
      "Epoch 74/300\n",
      "120/120 [==============================] - 0s 416us/sample - loss: 0.7920 - accuracy: 0.5667 - val_loss: 0.7997 - val_accuracy: 0.6000\n",
      "Epoch 75/300\n",
      "120/120 [==============================] - 0s 373us/sample - loss: 0.7877 - accuracy: 0.5667 - val_loss: 0.7959 - val_accuracy: 0.6000\n",
      "Epoch 76/300\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.7836 - accuracy: 0.5667 - val_loss: 0.7921 - val_accuracy: 0.6000\n",
      "Epoch 77/300\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 0.7795 - accuracy: 0.5583 - val_loss: 0.7884 - val_accuracy: 0.6000\n",
      "Epoch 78/300\n",
      "120/120 [==============================] - 0s 222us/sample - loss: 0.7752 - accuracy: 0.5500 - val_loss: 0.7845 - val_accuracy: 0.6000\n",
      "Epoch 79/300\n",
      "120/120 [==============================] - 0s 170us/sample - loss: 0.7711 - accuracy: 0.5583 - val_loss: 0.7806 - val_accuracy: 0.6000\n",
      "Epoch 80/300\n",
      "120/120 [==============================] - 0s 190us/sample - loss: 0.7670 - accuracy: 0.5583 - val_loss: 0.7768 - val_accuracy: 0.6000\n",
      "Epoch 81/300\n",
      "120/120 [==============================] - 0s 170us/sample - loss: 0.7630 - accuracy: 0.5583 - val_loss: 0.7732 - val_accuracy: 0.5667\n",
      "Epoch 82/300\n",
      "120/120 [==============================] - 0s 202us/sample - loss: 0.7588 - accuracy: 0.5500 - val_loss: 0.7694 - val_accuracy: 0.5667\n",
      "Epoch 83/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.7549 - accuracy: 0.5500 - val_loss: 0.7659 - val_accuracy: 0.5667\n",
      "Epoch 84/300\n",
      "120/120 [==============================] - 0s 306us/sample - loss: 0.7508 - accuracy: 0.5500 - val_loss: 0.7623 - val_accuracy: 0.5667\n",
      "Epoch 85/300\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.7468 - accuracy: 0.5500 - val_loss: 0.7587 - val_accuracy: 0.5667\n",
      "Epoch 86/300\n",
      "120/120 [==============================] - 0s 296us/sample - loss: 0.7430 - accuracy: 0.5500 - val_loss: 0.7553 - val_accuracy: 0.5333\n",
      "Epoch 87/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.7391 - accuracy: 0.5333 - val_loss: 0.7518 - val_accuracy: 0.5333\n",
      "Epoch 88/300\n",
      "120/120 [==============================] - 0s 309us/sample - loss: 0.7353 - accuracy: 0.5250 - val_loss: 0.7484 - val_accuracy: 0.5333\n",
      "Epoch 89/300\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.7313 - accuracy: 0.5250 - val_loss: 0.7449 - val_accuracy: 0.5333\n",
      "Epoch 90/300\n",
      "120/120 [==============================] - 0s 313us/sample - loss: 0.7275 - accuracy: 0.5333 - val_loss: 0.7415 - val_accuracy: 0.5333\n",
      "Epoch 91/300\n",
      "120/120 [==============================] - 0s 348us/sample - loss: 0.7238 - accuracy: 0.5333 - val_loss: 0.7381 - val_accuracy: 0.5333\n",
      "Epoch 92/300\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 0.7201 - accuracy: 0.5333 - val_loss: 0.7348 - val_accuracy: 0.5333\n",
      "Epoch 93/300\n",
      "120/120 [==============================] - 0s 344us/sample - loss: 0.7163 - accuracy: 0.5333 - val_loss: 0.7315 - val_accuracy: 0.5333\n",
      "Epoch 94/300\n",
      "120/120 [==============================] - 0s 339us/sample - loss: 0.7126 - accuracy: 0.5333 - val_loss: 0.7283 - val_accuracy: 0.5333\n",
      "Epoch 95/300\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.7090 - accuracy: 0.5250 - val_loss: 0.7252 - val_accuracy: 0.5333\n",
      "Epoch 96/300\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.7054 - accuracy: 0.5250 - val_loss: 0.7220 - val_accuracy: 0.5333\n",
      "Epoch 97/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.7019 - accuracy: 0.5250 - val_loss: 0.7188 - val_accuracy: 0.5333\n",
      "Epoch 98/300\n",
      "120/120 [==============================] - 0s 254us/sample - loss: 0.6983 - accuracy: 0.5417 - val_loss: 0.7157 - val_accuracy: 0.5333\n",
      "Epoch 99/300\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 0.6949 - accuracy: 0.5250 - val_loss: 0.7127 - val_accuracy: 0.5333\n",
      "Epoch 100/300\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.6913 - accuracy: 0.5417 - val_loss: 0.7097 - val_accuracy: 0.5000\n",
      "Epoch 101/300\n",
      "120/120 [==============================] - 0s 219us/sample - loss: 0.6880 - accuracy: 0.5417 - val_loss: 0.7067 - val_accuracy: 0.5333\n",
      "Epoch 102/300\n",
      "120/120 [==============================] - 0s 197us/sample - loss: 0.6845 - accuracy: 0.5500 - val_loss: 0.7036 - val_accuracy: 0.5667\n",
      "Epoch 103/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.6811 - accuracy: 0.5417 - val_loss: 0.7005 - val_accuracy: 0.5333\n",
      "Epoch 104/300\n",
      "120/120 [==============================] - 0s 180us/sample - loss: 0.6778 - accuracy: 0.5417 - val_loss: 0.6975 - val_accuracy: 0.5333\n",
      "Epoch 105/300\n",
      "120/120 [==============================] - 0s 206us/sample - loss: 0.6745 - accuracy: 0.5250 - val_loss: 0.6945 - val_accuracy: 0.5333\n",
      "Epoch 106/300\n",
      "120/120 [==============================] - 0s 195us/sample - loss: 0.6712 - accuracy: 0.5250 - val_loss: 0.6916 - val_accuracy: 0.5667\n",
      "Epoch 107/300\n",
      "120/120 [==============================] - 0s 350us/sample - loss: 0.6680 - accuracy: 0.5250 - val_loss: 0.6888 - val_accuracy: 0.6000\n",
      "Epoch 108/300\n",
      "120/120 [==============================] - 0s 177us/sample - loss: 0.6648 - accuracy: 0.5417 - val_loss: 0.6859 - val_accuracy: 0.6000\n",
      "Epoch 109/300\n",
      "120/120 [==============================] - 0s 149us/sample - loss: 0.6616 - accuracy: 0.5417 - val_loss: 0.6831 - val_accuracy: 0.6000\n",
      "Epoch 110/300\n",
      "120/120 [==============================] - 0s 190us/sample - loss: 0.6584 - accuracy: 0.5417 - val_loss: 0.6803 - val_accuracy: 0.6000\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 230us/sample - loss: 0.6553 - accuracy: 0.5417 - val_loss: 0.6776 - val_accuracy: 0.6000\n",
      "Epoch 112/300\n",
      "120/120 [==============================] - 0s 179us/sample - loss: 0.6523 - accuracy: 0.5500 - val_loss: 0.6749 - val_accuracy: 0.6000\n",
      "Epoch 113/300\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.6492 - accuracy: 0.5583 - val_loss: 0.6722 - val_accuracy: 0.6000\n",
      "Epoch 114/300\n",
      "120/120 [==============================] - 0s 163us/sample - loss: 0.6462 - accuracy: 0.5667 - val_loss: 0.6696 - val_accuracy: 0.5667\n",
      "Epoch 115/300\n",
      "120/120 [==============================] - 0s 185us/sample - loss: 0.6431 - accuracy: 0.5917 - val_loss: 0.6669 - val_accuracy: 0.5667\n",
      "Epoch 116/300\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 0.6402 - accuracy: 0.6083 - val_loss: 0.6643 - val_accuracy: 0.6000\n",
      "Epoch 117/300\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 0.6373 - accuracy: 0.6083 - val_loss: 0.6618 - val_accuracy: 0.6000\n",
      "Epoch 118/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.6343 - accuracy: 0.6333 - val_loss: 0.6592 - val_accuracy: 0.6000\n",
      "Epoch 119/300\n",
      "120/120 [==============================] - 0s 312us/sample - loss: 0.6315 - accuracy: 0.6417 - val_loss: 0.6567 - val_accuracy: 0.6000\n",
      "Epoch 120/300\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 0.6286 - accuracy: 0.6583 - val_loss: 0.6542 - val_accuracy: 0.6000\n",
      "Epoch 121/300\n",
      "120/120 [==============================] - 0s 336us/sample - loss: 0.6259 - accuracy: 0.6583 - val_loss: 0.6517 - val_accuracy: 0.6000\n",
      "Epoch 122/300\n",
      "120/120 [==============================] - 0s 464us/sample - loss: 0.6231 - accuracy: 0.6667 - val_loss: 0.6494 - val_accuracy: 0.6000\n",
      "Epoch 123/300\n",
      "120/120 [==============================] - 0s 325us/sample - loss: 0.6204 - accuracy: 0.6583 - val_loss: 0.6469 - val_accuracy: 0.6000\n",
      "Epoch 124/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.6176 - accuracy: 0.6667 - val_loss: 0.6445 - val_accuracy: 0.6000\n",
      "Epoch 125/300\n",
      "120/120 [==============================] - 0s 228us/sample - loss: 0.6150 - accuracy: 0.6583 - val_loss: 0.6422 - val_accuracy: 0.6000\n",
      "Epoch 126/300\n",
      "120/120 [==============================] - 0s 235us/sample - loss: 0.6122 - accuracy: 0.6750 - val_loss: 0.6399 - val_accuracy: 0.5667\n",
      "Epoch 127/300\n",
      "120/120 [==============================] - 0s 226us/sample - loss: 0.6096 - accuracy: 0.6750 - val_loss: 0.6375 - val_accuracy: 0.5667\n",
      "Epoch 128/300\n",
      "120/120 [==============================] - 0s 157us/sample - loss: 0.6073 - accuracy: 0.6750 - val_loss: 0.6355 - val_accuracy: 0.5667\n",
      "Epoch 129/300\n",
      "120/120 [==============================] - 0s 220us/sample - loss: 0.6044 - accuracy: 0.6750 - val_loss: 0.6332 - val_accuracy: 0.5667\n",
      "Epoch 130/300\n",
      "120/120 [==============================] - 0s 161us/sample - loss: 0.6020 - accuracy: 0.6750 - val_loss: 0.6310 - val_accuracy: 0.6000\n",
      "Epoch 131/300\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 0.5995 - accuracy: 0.6917 - val_loss: 0.6289 - val_accuracy: 0.6000\n",
      "Epoch 132/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.5970 - accuracy: 0.6917 - val_loss: 0.6268 - val_accuracy: 0.6000\n",
      "Epoch 133/300\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 0.5947 - accuracy: 0.7000 - val_loss: 0.6248 - val_accuracy: 0.6000\n",
      "Epoch 134/300\n",
      "120/120 [==============================] - 0s 187us/sample - loss: 0.5922 - accuracy: 0.7000 - val_loss: 0.6227 - val_accuracy: 0.6000\n",
      "Epoch 135/300\n",
      "120/120 [==============================] - 0s 168us/sample - loss: 0.5898 - accuracy: 0.7000 - val_loss: 0.6207 - val_accuracy: 0.6000\n",
      "Epoch 136/300\n",
      "120/120 [==============================] - 0s 189us/sample - loss: 0.5875 - accuracy: 0.7000 - val_loss: 0.6187 - val_accuracy: 0.6000\n",
      "Epoch 137/300\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.5852 - accuracy: 0.7000 - val_loss: 0.6167 - val_accuracy: 0.6000\n",
      "Epoch 138/300\n",
      "120/120 [==============================] - 0s 252us/sample - loss: 0.5829 - accuracy: 0.6917 - val_loss: 0.6148 - val_accuracy: 0.6000\n",
      "Epoch 139/300\n",
      "120/120 [==============================] - 0s 220us/sample - loss: 0.5807 - accuracy: 0.6917 - val_loss: 0.6129 - val_accuracy: 0.6333\n",
      "Epoch 140/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.5783 - accuracy: 0.6917 - val_loss: 0.6108 - val_accuracy: 0.6333\n",
      "Epoch 141/300\n",
      "120/120 [==============================] - 0s 319us/sample - loss: 0.5761 - accuracy: 0.6917 - val_loss: 0.6088 - val_accuracy: 0.6333\n",
      "Epoch 142/300\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.5741 - accuracy: 0.6917 - val_loss: 0.6070 - val_accuracy: 0.6333\n",
      "Epoch 143/300\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.5718 - accuracy: 0.6833 - val_loss: 0.6051 - val_accuracy: 0.6333\n",
      "Epoch 144/300\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.5696 - accuracy: 0.6833 - val_loss: 0.6033 - val_accuracy: 0.6333\n",
      "Epoch 145/300\n",
      "120/120 [==============================] - 0s 264us/sample - loss: 0.5675 - accuracy: 0.6667 - val_loss: 0.6014 - val_accuracy: 0.6333\n",
      "Epoch 146/300\n",
      "120/120 [==============================] - 0s 281us/sample - loss: 0.5655 - accuracy: 0.6667 - val_loss: 0.5997 - val_accuracy: 0.6000\n",
      "Epoch 147/300\n",
      "120/120 [==============================] - 0s 215us/sample - loss: 0.5634 - accuracy: 0.6667 - val_loss: 0.5979 - val_accuracy: 0.6000\n",
      "Epoch 148/300\n",
      "120/120 [==============================] - 0s 317us/sample - loss: 0.5614 - accuracy: 0.6667 - val_loss: 0.5962 - val_accuracy: 0.6000\n",
      "Epoch 149/300\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.5593 - accuracy: 0.6667 - val_loss: 0.5944 - val_accuracy: 0.6000\n",
      "Epoch 150/300\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.5573 - accuracy: 0.6667 - val_loss: 0.5924 - val_accuracy: 0.6000\n",
      "Epoch 151/300\n",
      "120/120 [==============================] - 0s 501us/sample - loss: 0.5554 - accuracy: 0.6667 - val_loss: 0.5905 - val_accuracy: 0.6000\n",
      "Epoch 152/300\n",
      "120/120 [==============================] - 0s 465us/sample - loss: 0.5534 - accuracy: 0.6667 - val_loss: 0.5888 - val_accuracy: 0.6000\n",
      "Epoch 153/300\n",
      "120/120 [==============================] - 0s 304us/sample - loss: 0.5515 - accuracy: 0.6667 - val_loss: 0.5871 - val_accuracy: 0.6000\n",
      "Epoch 154/300\n",
      "120/120 [==============================] - 0s 209us/sample - loss: 0.5497 - accuracy: 0.6667 - val_loss: 0.5855 - val_accuracy: 0.6000\n",
      "Epoch 155/300\n",
      "120/120 [==============================] - 0s 239us/sample - loss: 0.5477 - accuracy: 0.6667 - val_loss: 0.5838 - val_accuracy: 0.6000\n",
      "Epoch 156/300\n",
      "120/120 [==============================] - 0s 255us/sample - loss: 0.5460 - accuracy: 0.6667 - val_loss: 0.5823 - val_accuracy: 0.6000\n",
      "Epoch 157/300\n",
      "120/120 [==============================] - 0s 322us/sample - loss: 0.5440 - accuracy: 0.6667 - val_loss: 0.5807 - val_accuracy: 0.6000\n",
      "Epoch 158/300\n",
      "120/120 [==============================] - 0s 274us/sample - loss: 0.5422 - accuracy: 0.6667 - val_loss: 0.5791 - val_accuracy: 0.6000\n",
      "Epoch 159/300\n",
      "120/120 [==============================] - 0s 280us/sample - loss: 0.5404 - accuracy: 0.6667 - val_loss: 0.5773 - val_accuracy: 0.6000\n",
      "Epoch 160/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.5386 - accuracy: 0.6667 - val_loss: 0.5757 - val_accuracy: 0.6000\n",
      "Epoch 161/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.5368 - accuracy: 0.6667 - val_loss: 0.5740 - val_accuracy: 0.6000\n",
      "Epoch 162/300\n",
      "120/120 [==============================] - 0s 246us/sample - loss: 0.5350 - accuracy: 0.6667 - val_loss: 0.5724 - val_accuracy: 0.6000\n",
      "Epoch 163/300\n",
      "120/120 [==============================] - 0s 306us/sample - loss: 0.5333 - accuracy: 0.6667 - val_loss: 0.5707 - val_accuracy: 0.6000\n",
      "Epoch 164/300\n",
      "120/120 [==============================] - 0s 297us/sample - loss: 0.5316 - accuracy: 0.6667 - val_loss: 0.5693 - val_accuracy: 0.6000\n",
      "Epoch 165/300\n",
      "120/120 [==============================] - 0s 363us/sample - loss: 0.5299 - accuracy: 0.6667 - val_loss: 0.5677 - val_accuracy: 0.6000\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 396us/sample - loss: 0.5282 - accuracy: 0.6750 - val_loss: 0.5662 - val_accuracy: 0.6000\n",
      "Epoch 167/300\n",
      "120/120 [==============================] - 0s 505us/sample - loss: 0.5267 - accuracy: 0.6750 - val_loss: 0.5644 - val_accuracy: 0.6000\n",
      "Epoch 168/300\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.5249 - accuracy: 0.6750 - val_loss: 0.5631 - val_accuracy: 0.6000\n",
      "Epoch 169/300\n",
      "120/120 [==============================] - 0s 408us/sample - loss: 0.5232 - accuracy: 0.6750 - val_loss: 0.5617 - val_accuracy: 0.6000\n",
      "Epoch 170/300\n",
      "120/120 [==============================] - 0s 395us/sample - loss: 0.5216 - accuracy: 0.6750 - val_loss: 0.5601 - val_accuracy: 0.6000\n",
      "Epoch 171/300\n",
      "120/120 [==============================] - 0s 405us/sample - loss: 0.5200 - accuracy: 0.6750 - val_loss: 0.5587 - val_accuracy: 0.6000\n",
      "Epoch 172/300\n",
      "120/120 [==============================] - 0s 360us/sample - loss: 0.5184 - accuracy: 0.6750 - val_loss: 0.5570 - val_accuracy: 0.6000\n",
      "Epoch 173/300\n",
      "120/120 [==============================] - 0s 359us/sample - loss: 0.5169 - accuracy: 0.6750 - val_loss: 0.5556 - val_accuracy: 0.6000\n",
      "Epoch 174/300\n",
      "120/120 [==============================] - 0s 387us/sample - loss: 0.5152 - accuracy: 0.6750 - val_loss: 0.5541 - val_accuracy: 0.6000\n",
      "Epoch 175/300\n",
      "120/120 [==============================] - 0s 557us/sample - loss: 0.5136 - accuracy: 0.6750 - val_loss: 0.5526 - val_accuracy: 0.6000\n",
      "Epoch 176/300\n",
      "120/120 [==============================] - 0s 440us/sample - loss: 0.5121 - accuracy: 0.6750 - val_loss: 0.5511 - val_accuracy: 0.6000\n",
      "Epoch 177/300\n",
      "120/120 [==============================] - 0s 479us/sample - loss: 0.5106 - accuracy: 0.6833 - val_loss: 0.5495 - val_accuracy: 0.6000\n",
      "Epoch 178/300\n",
      "120/120 [==============================] - 0s 444us/sample - loss: 0.5091 - accuracy: 0.6833 - val_loss: 0.5482 - val_accuracy: 0.6000\n",
      "Epoch 179/300\n",
      "120/120 [==============================] - 0s 332us/sample - loss: 0.5075 - accuracy: 0.6833 - val_loss: 0.5467 - val_accuracy: 0.6000\n",
      "Epoch 180/300\n",
      "120/120 [==============================] - 0s 300us/sample - loss: 0.5060 - accuracy: 0.6833 - val_loss: 0.5450 - val_accuracy: 0.6000\n",
      "Epoch 181/300\n",
      "120/120 [==============================] - 0s 373us/sample - loss: 0.5046 - accuracy: 0.6917 - val_loss: 0.5436 - val_accuracy: 0.6000\n",
      "Epoch 182/300\n",
      "120/120 [==============================] - 0s 371us/sample - loss: 0.5030 - accuracy: 0.6917 - val_loss: 0.5421 - val_accuracy: 0.6000\n",
      "Epoch 183/300\n",
      "120/120 [==============================] - 0s 305us/sample - loss: 0.5016 - accuracy: 0.6917 - val_loss: 0.5405 - val_accuracy: 0.6000\n",
      "Epoch 184/300\n",
      "120/120 [==============================] - 0s 320us/sample - loss: 0.5001 - accuracy: 0.6917 - val_loss: 0.5391 - val_accuracy: 0.6000\n",
      "Epoch 185/300\n",
      "120/120 [==============================] - 0s 245us/sample - loss: 0.4987 - accuracy: 0.6917 - val_loss: 0.5378 - val_accuracy: 0.6000\n",
      "Epoch 186/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.4972 - accuracy: 0.6917 - val_loss: 0.5363 - val_accuracy: 0.6333\n",
      "Epoch 187/300\n",
      "120/120 [==============================] - 0s 247us/sample - loss: 0.4958 - accuracy: 0.6917 - val_loss: 0.5346 - val_accuracy: 0.6333\n",
      "Epoch 188/300\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 0.4943 - accuracy: 0.6917 - val_loss: 0.5331 - val_accuracy: 0.6333\n",
      "Epoch 189/300\n",
      "120/120 [==============================] - 0s 374us/sample - loss: 0.4929 - accuracy: 0.6917 - val_loss: 0.5316 - val_accuracy: 0.6333\n",
      "Epoch 190/300\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.4915 - accuracy: 0.6917 - val_loss: 0.5303 - val_accuracy: 0.6333\n",
      "Epoch 191/300\n",
      "120/120 [==============================] - 0s 321us/sample - loss: 0.4900 - accuracy: 0.7000 - val_loss: 0.5289 - val_accuracy: 0.6333\n",
      "Epoch 192/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.4886 - accuracy: 0.7000 - val_loss: 0.5274 - val_accuracy: 0.6333\n",
      "Epoch 193/300\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 0.4873 - accuracy: 0.7000 - val_loss: 0.5260 - val_accuracy: 0.6333\n",
      "Epoch 194/300\n",
      "120/120 [==============================] - 0s 323us/sample - loss: 0.4858 - accuracy: 0.7000 - val_loss: 0.5246 - val_accuracy: 0.6333\n",
      "Epoch 195/300\n",
      "120/120 [==============================] - 0s 307us/sample - loss: 0.4845 - accuracy: 0.7000 - val_loss: 0.5234 - val_accuracy: 0.6333\n",
      "Epoch 196/300\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 0.4831 - accuracy: 0.7000 - val_loss: 0.5220 - val_accuracy: 0.6667\n",
      "Epoch 197/300\n",
      "120/120 [==============================] - 0s 361us/sample - loss: 0.4817 - accuracy: 0.7000 - val_loss: 0.5203 - val_accuracy: 0.6667\n",
      "Epoch 198/300\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.4804 - accuracy: 0.7167 - val_loss: 0.5190 - val_accuracy: 0.6667\n",
      "Epoch 199/300\n",
      "120/120 [==============================] - 0s 382us/sample - loss: 0.4790 - accuracy: 0.7167 - val_loss: 0.5174 - val_accuracy: 0.6667\n",
      "Epoch 200/300\n",
      "120/120 [==============================] - 0s 371us/sample - loss: 0.4777 - accuracy: 0.7167 - val_loss: 0.5158 - val_accuracy: 0.7000\n",
      "Epoch 201/300\n",
      "120/120 [==============================] - 0s 353us/sample - loss: 0.4763 - accuracy: 0.7167 - val_loss: 0.5144 - val_accuracy: 0.7000\n",
      "Epoch 202/300\n",
      "120/120 [==============================] - 0s 341us/sample - loss: 0.4750 - accuracy: 0.7167 - val_loss: 0.5131 - val_accuracy: 0.7000\n",
      "Epoch 203/300\n",
      "120/120 [==============================] - 0s 342us/sample - loss: 0.4736 - accuracy: 0.7167 - val_loss: 0.5119 - val_accuracy: 0.7000\n",
      "Epoch 204/300\n",
      "120/120 [==============================] - 0s 311us/sample - loss: 0.4723 - accuracy: 0.7167 - val_loss: 0.5106 - val_accuracy: 0.7000\n",
      "Epoch 205/300\n",
      "120/120 [==============================] - 0s 358us/sample - loss: 0.4710 - accuracy: 0.7167 - val_loss: 0.5091 - val_accuracy: 0.7000\n",
      "Epoch 206/300\n",
      "120/120 [==============================] - 0s 329us/sample - loss: 0.4696 - accuracy: 0.7167 - val_loss: 0.5078 - val_accuracy: 0.7000\n",
      "Epoch 207/300\n",
      "120/120 [==============================] - 0s 342us/sample - loss: 0.4683 - accuracy: 0.7167 - val_loss: 0.5064 - val_accuracy: 0.7333\n",
      "Epoch 208/300\n",
      "120/120 [==============================] - 0s 312us/sample - loss: 0.4669 - accuracy: 0.7167 - val_loss: 0.5049 - val_accuracy: 0.7667\n",
      "Epoch 209/300\n",
      "120/120 [==============================] - 0s 323us/sample - loss: 0.4656 - accuracy: 0.7167 - val_loss: 0.5033 - val_accuracy: 0.7667\n",
      "Epoch 210/300\n",
      "120/120 [==============================] - 0s 335us/sample - loss: 0.4643 - accuracy: 0.7167 - val_loss: 0.5016 - val_accuracy: 0.8333\n",
      "Epoch 211/300\n",
      "120/120 [==============================] - 0s 472us/sample - loss: 0.4630 - accuracy: 0.7333 - val_loss: 0.5000 - val_accuracy: 0.8333\n",
      "Epoch 212/300\n",
      "120/120 [==============================] - 0s 709us/sample - loss: 0.4617 - accuracy: 0.7417 - val_loss: 0.4988 - val_accuracy: 0.8333\n",
      "Epoch 213/300\n",
      "120/120 [==============================] - 0s 293us/sample - loss: 0.4603 - accuracy: 0.7500 - val_loss: 0.4972 - val_accuracy: 0.8333\n",
      "Epoch 214/300\n",
      "120/120 [==============================] - 0s 532us/sample - loss: 0.4590 - accuracy: 0.7583 - val_loss: 0.4959 - val_accuracy: 0.8333\n",
      "Epoch 215/300\n",
      "120/120 [==============================] - 0s 311us/sample - loss: 0.4576 - accuracy: 0.7750 - val_loss: 0.4945 - val_accuracy: 0.8333\n",
      "Epoch 216/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.4563 - accuracy: 0.7750 - val_loss: 0.4931 - val_accuracy: 0.8333\n",
      "Epoch 217/300\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.4550 - accuracy: 0.7750 - val_loss: 0.4918 - val_accuracy: 0.8333\n",
      "Epoch 218/300\n",
      "120/120 [==============================] - 0s 551us/sample - loss: 0.4537 - accuracy: 0.7750 - val_loss: 0.4903 - val_accuracy: 0.8333\n",
      "Epoch 219/300\n",
      "120/120 [==============================] - 0s 518us/sample - loss: 0.4526 - accuracy: 0.7833 - val_loss: 0.4892 - val_accuracy: 0.8333\n",
      "Epoch 220/300\n",
      "120/120 [==============================] - 0s 830us/sample - loss: 0.4511 - accuracy: 0.7833 - val_loss: 0.4877 - val_accuracy: 0.8333\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 303us/sample - loss: 0.4499 - accuracy: 0.7833 - val_loss: 0.4862 - val_accuracy: 0.8333\n",
      "Epoch 222/300\n",
      "120/120 [==============================] - 0s 297us/sample - loss: 0.4485 - accuracy: 0.7917 - val_loss: 0.4847 - val_accuracy: 0.8333\n",
      "Epoch 223/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.4831 - val_accuracy: 0.8333\n",
      "Epoch 224/300\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.4459 - accuracy: 0.8000 - val_loss: 0.4819 - val_accuracy: 0.8333\n",
      "Epoch 225/300\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.4446 - accuracy: 0.8083 - val_loss: 0.4806 - val_accuracy: 0.8333\n",
      "Epoch 226/300\n",
      "120/120 [==============================] - 0s 262us/sample - loss: 0.4433 - accuracy: 0.8167 - val_loss: 0.4791 - val_accuracy: 0.8333\n",
      "Epoch 227/300\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 0.4420 - accuracy: 0.8167 - val_loss: 0.4776 - val_accuracy: 0.8333\n",
      "Epoch 228/300\n",
      "120/120 [==============================] - 0s 268us/sample - loss: 0.4407 - accuracy: 0.8333 - val_loss: 0.4762 - val_accuracy: 0.8333\n",
      "Epoch 229/300\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.4394 - accuracy: 0.8333 - val_loss: 0.4748 - val_accuracy: 0.8333\n",
      "Epoch 230/300\n",
      "120/120 [==============================] - 0s 373us/sample - loss: 0.4382 - accuracy: 0.8333 - val_loss: 0.4733 - val_accuracy: 0.8333\n",
      "Epoch 231/300\n",
      "120/120 [==============================] - 0s 297us/sample - loss: 0.4369 - accuracy: 0.8417 - val_loss: 0.4718 - val_accuracy: 0.8333\n",
      "Epoch 232/300\n",
      "120/120 [==============================] - 0s 263us/sample - loss: 0.4356 - accuracy: 0.8500 - val_loss: 0.4703 - val_accuracy: 0.8333\n",
      "Epoch 233/300\n",
      "120/120 [==============================] - 0s 293us/sample - loss: 0.4343 - accuracy: 0.8500 - val_loss: 0.4691 - val_accuracy: 0.8333\n",
      "Epoch 234/300\n",
      "120/120 [==============================] - 0s 305us/sample - loss: 0.4330 - accuracy: 0.8500 - val_loss: 0.4677 - val_accuracy: 0.8333\n",
      "Epoch 235/300\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.4317 - accuracy: 0.8500 - val_loss: 0.4665 - val_accuracy: 0.8667\n",
      "Epoch 236/300\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 0.4304 - accuracy: 0.8667 - val_loss: 0.4650 - val_accuracy: 0.8667\n",
      "Epoch 237/300\n",
      "120/120 [==============================] - 0s 350us/sample - loss: 0.4291 - accuracy: 0.8833 - val_loss: 0.4636 - val_accuracy: 0.8667\n",
      "Epoch 238/300\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.4279 - accuracy: 0.8833 - val_loss: 0.4621 - val_accuracy: 0.8667\n",
      "Epoch 239/300\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.4266 - accuracy: 0.8833 - val_loss: 0.4606 - val_accuracy: 0.8667\n",
      "Epoch 240/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.4253 - accuracy: 0.8833 - val_loss: 0.4592 - val_accuracy: 0.8667\n",
      "Epoch 241/300\n",
      "120/120 [==============================] - 0s 302us/sample - loss: 0.4240 - accuracy: 0.8833 - val_loss: 0.4583 - val_accuracy: 0.8667\n",
      "Epoch 242/300\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.4227 - accuracy: 0.8833 - val_loss: 0.4569 - val_accuracy: 0.8667\n",
      "Epoch 243/300\n",
      "120/120 [==============================] - 0s 279us/sample - loss: 0.4214 - accuracy: 0.8917 - val_loss: 0.4556 - val_accuracy: 0.8667\n",
      "Epoch 244/300\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.4201 - accuracy: 0.8917 - val_loss: 0.4545 - val_accuracy: 0.8667\n",
      "Epoch 245/300\n",
      "120/120 [==============================] - 0s 303us/sample - loss: 0.4189 - accuracy: 0.8917 - val_loss: 0.4534 - val_accuracy: 0.8667\n",
      "Epoch 246/300\n",
      "120/120 [==============================] - 0s 273us/sample - loss: 0.4176 - accuracy: 0.8917 - val_loss: 0.4523 - val_accuracy: 0.8667\n",
      "Epoch 247/300\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.4164 - accuracy: 0.8917 - val_loss: 0.4508 - val_accuracy: 0.8667\n",
      "Epoch 248/300\n",
      "120/120 [==============================] - 0s 253us/sample - loss: 0.4152 - accuracy: 0.8917 - val_loss: 0.4490 - val_accuracy: 0.9333\n",
      "Epoch 249/300\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 0.4138 - accuracy: 0.8917 - val_loss: 0.4478 - val_accuracy: 0.9333\n",
      "Epoch 250/300\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 0.4125 - accuracy: 0.8917 - val_loss: 0.4462 - val_accuracy: 0.9333\n",
      "Epoch 251/300\n",
      "120/120 [==============================] - 0s 270us/sample - loss: 0.4112 - accuracy: 0.8917 - val_loss: 0.4446 - val_accuracy: 0.9333\n",
      "Epoch 252/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.4100 - accuracy: 0.8917 - val_loss: 0.4432 - val_accuracy: 0.9333\n",
      "Epoch 253/300\n",
      "120/120 [==============================] - 0s 296us/sample - loss: 0.4086 - accuracy: 0.8917 - val_loss: 0.4417 - val_accuracy: 0.9333\n",
      "Epoch 254/300\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.4074 - accuracy: 0.8917 - val_loss: 0.4402 - val_accuracy: 0.9333\n",
      "Epoch 255/300\n",
      "120/120 [==============================] - 0s 295us/sample - loss: 0.4061 - accuracy: 0.8917 - val_loss: 0.4387 - val_accuracy: 0.9333\n",
      "Epoch 256/300\n",
      "120/120 [==============================] - 0s 238us/sample - loss: 0.4050 - accuracy: 0.9000 - val_loss: 0.4371 - val_accuracy: 0.9333\n",
      "Epoch 257/300\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 0.4036 - accuracy: 0.9000 - val_loss: 0.4361 - val_accuracy: 0.9333\n",
      "Epoch 258/300\n",
      "120/120 [==============================] - 0s 174us/sample - loss: 0.4023 - accuracy: 0.9000 - val_loss: 0.4348 - val_accuracy: 0.9333\n",
      "Epoch 259/300\n",
      "120/120 [==============================] - 0s 240us/sample - loss: 0.4010 - accuracy: 0.9000 - val_loss: 0.4336 - val_accuracy: 0.9333\n",
      "Epoch 260/300\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 0.4001 - accuracy: 0.9083 - val_loss: 0.4327 - val_accuracy: 0.9333\n",
      "Epoch 261/300\n",
      "120/120 [==============================] - 0s 284us/sample - loss: 0.3986 - accuracy: 0.9000 - val_loss: 0.4308 - val_accuracy: 0.9333\n",
      "Epoch 262/300\n",
      "120/120 [==============================] - 0s 303us/sample - loss: 0.3973 - accuracy: 0.9167 - val_loss: 0.4295 - val_accuracy: 0.9333\n",
      "Epoch 263/300\n",
      "120/120 [==============================] - 0s 349us/sample - loss: 0.3960 - accuracy: 0.9083 - val_loss: 0.4279 - val_accuracy: 0.9333\n",
      "Epoch 264/300\n",
      "120/120 [==============================] - 0s 328us/sample - loss: 0.3947 - accuracy: 0.9083 - val_loss: 0.4265 - val_accuracy: 0.9333\n",
      "Epoch 265/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.3935 - accuracy: 0.9083 - val_loss: 0.4249 - val_accuracy: 0.9333\n",
      "Epoch 266/300\n",
      "120/120 [==============================] - 0s 325us/sample - loss: 0.3923 - accuracy: 0.9083 - val_loss: 0.4230 - val_accuracy: 0.9333\n",
      "Epoch 267/300\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 0.3909 - accuracy: 0.9167 - val_loss: 0.4216 - val_accuracy: 0.9333\n",
      "Epoch 268/300\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 0.3898 - accuracy: 0.9167 - val_loss: 0.4203 - val_accuracy: 0.9333\n",
      "Epoch 269/300\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.3885 - accuracy: 0.9250 - val_loss: 0.4188 - val_accuracy: 0.9333\n",
      "Epoch 270/300\n",
      "120/120 [==============================] - 0s 291us/sample - loss: 0.3873 - accuracy: 0.9250 - val_loss: 0.4176 - val_accuracy: 0.9333\n",
      "Epoch 271/300\n",
      "120/120 [==============================] - 0s 296us/sample - loss: 0.3861 - accuracy: 0.9250 - val_loss: 0.4160 - val_accuracy: 0.9333\n",
      "Epoch 272/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.3847 - accuracy: 0.9250 - val_loss: 0.4150 - val_accuracy: 0.9333\n",
      "Epoch 273/300\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 0.3835 - accuracy: 0.9250 - val_loss: 0.4136 - val_accuracy: 0.9333\n",
      "Epoch 274/300\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.3823 - accuracy: 0.9250 - val_loss: 0.4124 - val_accuracy: 0.9333\n",
      "Epoch 275/300\n",
      "120/120 [==============================] - 0s 328us/sample - loss: 0.3810 - accuracy: 0.9250 - val_loss: 0.4111 - val_accuracy: 0.9333\n",
      "Epoch 276/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 237us/sample - loss: 0.3798 - accuracy: 0.9333 - val_loss: 0.4099 - val_accuracy: 0.9333\n",
      "Epoch 277/300\n",
      "120/120 [==============================] - 0s 298us/sample - loss: 0.3786 - accuracy: 0.9417 - val_loss: 0.4085 - val_accuracy: 0.9333\n",
      "Epoch 278/300\n",
      "120/120 [==============================] - 0s 236us/sample - loss: 0.3774 - accuracy: 0.9417 - val_loss: 0.4076 - val_accuracy: 0.9333\n",
      "Epoch 279/300\n",
      "120/120 [==============================] - 0s 248us/sample - loss: 0.3761 - accuracy: 0.9417 - val_loss: 0.4060 - val_accuracy: 0.9333\n",
      "Epoch 280/300\n",
      "120/120 [==============================] - 0s 229us/sample - loss: 0.3749 - accuracy: 0.9417 - val_loss: 0.4047 - val_accuracy: 0.9333\n",
      "Epoch 281/300\n",
      "120/120 [==============================] - 0s 294us/sample - loss: 0.3736 - accuracy: 0.9417 - val_loss: 0.4034 - val_accuracy: 0.9333\n",
      "Epoch 282/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.3140 - accuracy: 0.96 - 0s 254us/sample - loss: 0.3724 - accuracy: 0.9417 - val_loss: 0.4021 - val_accuracy: 0.9333\n",
      "Epoch 283/300\n",
      "120/120 [==============================] - 0s 251us/sample - loss: 0.3712 - accuracy: 0.9500 - val_loss: 0.4004 - val_accuracy: 0.9333\n",
      "Epoch 284/300\n",
      "120/120 [==============================] - 0s 290us/sample - loss: 0.3700 - accuracy: 0.9500 - val_loss: 0.3991 - val_accuracy: 0.9333\n",
      "Epoch 285/300\n",
      "120/120 [==============================] - 0s 286us/sample - loss: 0.3688 - accuracy: 0.9500 - val_loss: 0.3979 - val_accuracy: 0.9333\n",
      "Epoch 286/300\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 0.3675 - accuracy: 0.9500 - val_loss: 0.3966 - val_accuracy: 0.9333\n",
      "Epoch 287/300\n",
      "120/120 [==============================] - 0s 205us/sample - loss: 0.3663 - accuracy: 0.9500 - val_loss: 0.3953 - val_accuracy: 0.9333\n",
      "Epoch 288/300\n",
      "120/120 [==============================] - 0s 282us/sample - loss: 0.3651 - accuracy: 0.9500 - val_loss: 0.3940 - val_accuracy: 0.9333\n",
      "Epoch 289/300\n",
      "120/120 [==============================] - 0s 292us/sample - loss: 0.3638 - accuracy: 0.9500 - val_loss: 0.3929 - val_accuracy: 0.9333\n",
      "Epoch 290/300\n",
      "120/120 [==============================] - 0s 191us/sample - loss: 0.3626 - accuracy: 0.9500 - val_loss: 0.3918 - val_accuracy: 0.9333\n",
      "Epoch 291/300\n",
      "120/120 [==============================] - 0s 278us/sample - loss: 0.3614 - accuracy: 0.9500 - val_loss: 0.3909 - val_accuracy: 0.9333\n",
      "Epoch 292/300\n",
      "120/120 [==============================] - 0s 370us/sample - loss: 0.3603 - accuracy: 0.9500 - val_loss: 0.3899 - val_accuracy: 0.9333\n",
      "Epoch 293/300\n",
      "120/120 [==============================] - 0s 257us/sample - loss: 0.3590 - accuracy: 0.9500 - val_loss: 0.3886 - val_accuracy: 0.9333\n",
      "Epoch 294/300\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.3578 - accuracy: 0.9500 - val_loss: 0.3875 - val_accuracy: 0.9333\n",
      "Epoch 295/300\n",
      "120/120 [==============================] - 0s 277us/sample - loss: 0.3566 - accuracy: 0.9500 - val_loss: 0.3863 - val_accuracy: 0.9333\n",
      "Epoch 296/300\n",
      "120/120 [==============================] - 0s 170us/sample - loss: 0.3554 - accuracy: 0.9500 - val_loss: 0.3851 - val_accuracy: 0.9333\n",
      "Epoch 297/300\n",
      "120/120 [==============================] - 0s 231us/sample - loss: 0.3542 - accuracy: 0.9500 - val_loss: 0.3837 - val_accuracy: 0.9333\n",
      "Epoch 298/300\n",
      "120/120 [==============================] - 0s 346us/sample - loss: 0.3530 - accuracy: 0.9500 - val_loss: 0.3825 - val_accuracy: 0.9333\n",
      "Epoch 299/300\n",
      "120/120 [==============================] - 0s 318us/sample - loss: 0.3517 - accuracy: 0.9500 - val_loss: 0.3811 - val_accuracy: 0.9333\n",
      "Epoch 300/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.3505 - accuracy: 0.9500 - val_loss: 0.3797 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13c120dd0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train, \n",
    "          y=y_train, \n",
    "          epochs=300,\n",
    "          validation_data=(scaled_X_test, y_test), verbose=1 ,callbacks=[early_stop]         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_iris_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler,'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#THIS SOME STUFF_________------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('final_iris_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower = [[5.1, 3.5, 1.4, 0.2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(flower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['setosa', 'versicolor', 'viriginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ind = model.predict_classes(flower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[class_ind[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {\n",
    "\"sepal_length\":5.1,\n",
    "\"sepal_width\":3.5,\n",
    "\"petal_length\":1.4,\n",
    "\"petal_width\":0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {\n",
    "\"sepal_length\":5.1,\n",
    "\"sepal_width\":3.5,\n",
    "\"petal_length\":1.4,\n",
    "\"petal_width\":0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = requests.post(\"http://localhost:5000/run\", json=flower_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n    <meta charset=\"UTF-8\">\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\\n    <title>ML_Proj</title>\\n</head>\\n<body>\\n    <h1>setosa</h1>\\n</body>\\n</html>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
